# Sparky

**AI-Powered Development Activity Monitor & Content Generator for raibid-labs**

Sparky is an autonomous system that monitors git activity across all raibid-labs repositories, generates intelligent summaries, and produces engaging content for blogs and social media.

**Project Status:** Design Phase Complete - 100% OSS Implementation Ready
**Last Updated:** 2025-11-12

---

## What is Sparky?

Sparky transforms raw development activity into compelling narratives using **100% open-source tools** with **zero external costs**.

- **Monitors** git activity across 28+ raibid-labs repositories (GitHub CLI)
- **Analyzes** commits, PRs, issues using **local LLM** (Ollama + Qwen2.5-Coder)
- **Generates** daily digests, weekly reports, and monthly reviews
- **Publishes** content to docs, blogs, and social media
- **Automates** the entire pipeline with zero manual intervention

**No API costs. No external dependencies. Runs completely locally.**

## Quick Start (15 Minutes)

```bash
# 1. Install Ollama
curl -fsSL https://ollama.com/install.sh | sh

# 2. Pull model (1.1GB, one-time)
ollama pull qwen2.5-coder:1.5b

# 3. Collect today's data (free, no API limits)
./docs/examples/collect-gh.sh

# 4. Generate summary (local AI, free)
python3 docs/examples/analyze-ollama.py

# Done! View output
cat output/daily/$(date +%Y-%m-%d).md
```

**See [QUICKSTART_OSS.md](./QUICKSTART_OSS.md) for detailed guide.**

## Architecture Overview

```
GitHub Repos (28+)
    ‚Üì
Data Collectors (6 parallel agents)
    ‚Üì
Analyzers (4 parallel agents)
    ‚Üì
Content Generators (3 parallel agents)
    ‚Üì
Publishers (docs, blog, social media)
```

**Pipeline Duration:** ~15-20 minutes end-to-end

## Core Features

### 1. Automated Data Collection
- Monitors all raibid-labs repositories
- Collects commits, PRs, issues, releases
- Concurrent collection (6 repos at a time)
- GitHub GraphQL API for efficiency
- Rate limit management (5000 req/hr)

### 2. Intelligent Analysis
- AI-powered semantic analysis (Claude API)
- Activity metrics (commits/day, PR velocity)
- Trend detection (productivity patterns)
- Impact scoring (change significance)
- Contributor profiling

### 3. Content Generation
- **Daily Digest:** 200-300 words, key highlights
- **Weekly Report:** 800-1200 words, comprehensive overview
- **Monthly Review:** 2000-3000 words, in-depth analysis
- **Blog Posts:** 1500-2500 words, polished content
- **Social Media:** Twitter/LinkedIn posts

### 4. Multi-Channel Publishing
- raibid-labs/docs repository (internal)
- Dev.to (external blog)
- Twitter/LinkedIn (social engagement)
- GitHub Issues/Comments (team updates)

## Documentation

### üöÄ Start Here

| Document | Description | Time |
|----------|-------------|------|
| **[OSS Quick Start](./QUICKSTART_OSS.md)** | Get running in 15 minutes | ‚≠ê 15 min |
| [OSS Deployment Strategy](./docs/OSS_DEPLOYMENT_STRATEGY.md) | Complete technical guide | 30 min |
| [Infrastructure Guide](./docs/README_INFRASTRUCTURE.md) | DGX integration & K8s | 20 min |

### Core Documentation

| Document | Description |
|----------|-------------|
| [Zero-Cost Architecture](./docs/zero-cost-architecture.md) | OSS design decisions, approaches |
| [Model Research](./research/git-commit-summarization-oss-models.md) | Best OSS models for summarization |
| [Architecture (Original)](./docs/architecture.md) | Full system design |
| [Parallel Workstreams](./docs/parallel-workstreams.md) | Development organization |

### Additional Research

These documents informed the design (optional reading):

| Resource | Description |
|----------|-------------|
| [Research Report](./RESEARCH_REPORT_DEV_AUTOMATION_2025.md) | External market research |
| [Executive Summary](./EXECUTIVE_SUMMARY.md) | High-level findings |
| [Tools & Libraries](./TOOLS_AND_LIBRARIES.md) | 100+ tools catalog |

---

## Technology Stack (100% OSS)

### Core Technologies
- **Data Collection:** GitHub CLI (gh) - free, no API limits
- **LLM Inference:** Ollama + Qwen2.5-Coder-1.5B (local, Apache 2.0)
- **Alternative LLM:** vLLM (production-grade, 10x faster)
- **Orchestration:** Cron / GitHub Actions + self-hosted runner
- **Storage:** Git repository (JSON + Markdown files)
- **Scripting:** Bash + Python
- **Infrastructure:** Docker + Kubernetes (optional)

### Why This Stack?
- ‚úÖ **$0/month** operating cost
- ‚úÖ **No API rate limits** (GitHub CLI is special)
- ‚úÖ **Full data privacy** (everything runs locally)
- ‚úÖ **Fast inference** (< 1 second per summary)
- ‚úÖ **High quality** (code-specialized models)
- ‚úÖ **Easy deployment** (works on existing DGX infrastructure)

### Integration with DGX Infrastructure
- **dgx-spark-playbooks:** Deployment patterns (Ollama, vLLM, Docker)
- **Kubernetes:** Optional K8s deployment using existing K3s cluster
- **Docker:** Containerized services for isolation
- **GPU:** Efficient inference using NVIDIA GPUs

---

## Development Roadmap

### Phase 0: Bootstrap (Days 1-2)
- [x] Research and architecture design
- [x] Create documentation
- [ ] Initialize repository structure
- [ ] Set up GitHub Actions workflows
- [ ] Configure secrets and environment

### Phase 1: Parallel Workstreams (Days 3-9)
**All workstreams execute concurrently:**

- [ ] **Workstream 1:** Orchestration & Infrastructure
- [ ] **Workstream 2:** Data Collection System
- [ ] **Workstream 3:** Analysis Engine
- [ ] **Workstream 4:** Content Generation Pipeline

### Phase 2: Integration & Testing (Days 10-13)
- [ ] End-to-end pipeline testing
- [ ] Integration tests across workstreams
- [ ] Performance optimization
- [ ] Security audit

### Phase 3: Deployment & Documentation (Days 14-15)
- [ ] Production deployment
- [ ] Monitoring setup
- [ ] User guides and runbooks
- [ ] Launch first daily/weekly/monthly report

**Target Timeline:** 15 days (3 weeks)

---

## Parallel Workstream Organization

Sparky development is split into **4 independent workstreams** that can be executed concurrently:

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ   Workstream 1      ‚îÇ   Workstream 2      ‚îÇ   Workstream 3      ‚îÇ   Workstream 4      ‚îÇ
‚îÇ   Orchestration     ‚îÇ   Collection        ‚îÇ   Analysis          ‚îÇ   Generation        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ GitHub Actions      ‚îÇ GitHub API          ‚îÇ AI Integration      ‚îÇ Content Templates   ‚îÇ
‚îÇ Monitoring          ‚îÇ Data Models         ‚îÇ Metrics Calculation ‚îÇ Publishing          ‚îÇ
‚îÇ Health Checks       ‚îÇ Rate Limiting       ‚îÇ Insight Generation  ‚îÇ Multi-Format Output ‚îÇ
‚îÇ Agent Spawning      ‚îÇ Storage Layer       ‚îÇ Pattern Detection   ‚îÇ Social Media        ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Owns:               ‚îÇ Owns:               ‚îÇ Owns:               ‚îÇ Owns:               ‚îÇ
‚îÇ .github/workflows/  ‚îÇ collectors/         ‚îÇ analyzers/          ‚îÇ generators/         ‚îÇ
‚îÇ scripts/            ‚îÇ api/                ‚îÇ ai/                 ‚îÇ templates/          ‚îÇ
‚îÇ monitoring/         ‚îÇ models/             ‚îÇ analytics/          ‚îÇ publishers/         ‚îÇ
‚îÇ                     ‚îÇ storage/            ‚îÇ insights/           ‚îÇ content/            ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Agent:              ‚îÇ Agent:              ‚îÇ Agent:              ‚îÇ Agent:              ‚îÇ
‚îÇ devops-automator    ‚îÇ backend-architect   ‚îÇ ai-engineer         ‚îÇ frontend-developer  ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ Duration: 3-5 days  ‚îÇ Duration: 4-6 days  ‚îÇ Duration: 4-6 days  ‚îÇ Duration: 4-6 days  ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

**Benefits:**
- Parallel execution (4x faster than sequential)
- Clear ownership (prevents conflicts)
- Independent testing (each workstream validated separately)
- Flexible staffing (4 agents or developers working simultaneously)

See [Parallel Workstreams](./docs/parallel-workstreams.md) for detailed breakdown.

---

## Cost Analysis

### 100% OSS Stack (Current)

```
Ollama (local LLM):   $0/month (self-hosted)
GitHub CLI:           $0/month (free, no limits)
Storage (git):        $0/month (repository)
Electricity:          ~$0.50/month (minimal GPU usage)
Total:                ~$0.50/month
```

### Comparison to API-Based Approach

| Component | API-Based | OSS |
|-----------|-----------|-----|
| LLM Inference | $15-45/mo (Claude API) | **$0** (Ollama) |
| GitHub Data | $0 (rate limited) | **$0** (gh CLI, unlimited) |
| Storage | $0-25/mo (database) | **$0** (git) |
| Infrastructure | $0-20/mo (cloud) | **$0** (existing DGX) |
| **Total** | **$15-90/mo** | **~$0.50/mo** |

**Savings: $14.50 - $89.50/month**

### Quality Comparison

| Model | Quality | Speed | Monthly Cost |
|-------|---------|-------|--------------|
| GPT-4 API | 9/10 | 5-10s | $30-60 |
| Claude 3.5 API | 9.5/10 | 3-5s | $15-45 |
| **Qwen2.5-Coder-1.5B** | **8.5/10** | **<1s** | **$0** |

**For git commit summarization:** Code-specialized models like Qwen2.5-Coder are actually better than general-purpose LLMs while being free and 10x faster.

---

## Acknowledgments

Sparky builds on proven patterns from across the raibid-labs organization:

- **raibid-ci:** Event-driven orchestration
- **raibid-cli:** Multi-repository management
- **XPTui:** Parallel agent coordination
- **MOP:** Advanced meta-orchestrator
- **docs:** Documentation aggregation
- **agents:** Claude Code sub-agents framework

Special thanks to all raibid-labs contributors whose work made this possible.

---

## License

MIT License - See [LICENSE](./LICENSE) file

## Contact

- **GitHub Issues:** [raibid-labs/sparky/issues](https://github.com/raibid-labs/sparky/issues)
- **Organization:** [raibid-labs](https://github.com/raibid-labs)
- **Documentation:** [raibid-labs.github.io/docs](https://raibid-labs.github.io/docs)

---

**Status:** Design Phase Complete | Ready for Phase 0 Bootstrap

**Last Updated:** 2025-11-12
